{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_path = Path(\"D:/Kaggle/NLP/train.csv\")\n",
    "test_path = Path(\"D:/Kaggle/NLP/test.csv\")\n",
    "train=pd.read_csv(train_path)\n",
    "test=pd.read_csv(test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string \n",
    "def processTweet(tweet):\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet = re.sub(r'[' + string.punctuation + ']+', ' ', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ') \n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF') \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean dataframe's text column\n",
    "train['text'] = train['text'].apply(processTweet)\n",
    "test['text'] = test['text'].apply(processTweet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason this may allah forgiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked shelter place are being no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000 people receive evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby smoke from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7608</td>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding bridge collapse into ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7609</td>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the out control wild fires california even the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7610</td>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>utc 5km volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7611</td>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating after bike collided with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7612</td>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest more homes razed northern californi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason this may allah forgiv...       1  \n",
       "1                    forest fire near ronge sask canada       1  \n",
       "2     all residents asked shelter place are being no...       1  \n",
       "3      000 people receive evacuation orders california        1  \n",
       "4     just got sent this photo from ruby smoke from ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  two giant cranes holding bridge collapse into ...       1  \n",
       "7609  the out control wild fires california even the...       1  \n",
       "7610                            utc 5km volcano hawaii        1  \n",
       "7611  police investigating after bike collided with ...       1  \n",
       "7612  the latest more homes razed northern californi...       1  \n",
       "\n",
       "[3271 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['target']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.text\n",
    "y_train=train.target\n",
    "X_test=test.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline                         #Pipe\n",
    "#from sklearn.naive_bayes import MultinomialNB                # Training Naive Bayes (NB) classifier on training data.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  #TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer   # Extracting features from text files\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2)))\n",
    "                     , ('tfidf', TfidfTransformer())\n",
    "                     , ('LGBMmodel', LGBMClassifier(n_estimators=3000,learning_rate=0.03))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'LGBMmodel__alpha': (1e-2, 1e-3),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do 10-fold cross validation for each of the 8 possible combinations of the above params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, cv=10, param_grid=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 26.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: 0.645081 using {'LGBMmodel__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Mean: 0.638250 Stdev:(0.050782) with: {'LGBMmodel__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "Mean: 0.641797 Stdev:(0.060752) with: {'LGBMmodel__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "Mean: 0.639695 Stdev:(0.060149) with: {'LGBMmodel__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Mean: 0.645081 Stdev:(0.060391) with: {'LGBMmodel__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n",
      "Mean: 0.638250 Stdev:(0.050782) with: {'LGBMmodel__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "Mean: 0.641797 Stdev:(0.060752) with: {'LGBMmodel__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "Mean: 0.639695 Stdev:(0.060149) with: {'LGBMmodel__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Mean: 0.645081 Stdev:(0.060391) with: {'LGBMmodel__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"\\nBest Model: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print('\\n')\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean: %f Stdev:(%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                colsample_bytree=1.0, importance_type='split',\n",
       "                                learning_rate=0.03, max_depth=-1,\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=3000,\n",
       "                                n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                random_state=None, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4270,   72],\n",
       "       [ 247, 3024]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred=pipe.predict(X_train)\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.902     0.966     0.933      4342\n",
      "           1      0.951     0.861     0.904      3271\n",
      "\n",
      "    accuracy                          0.921      7613\n",
      "   macro avg      0.927     0.914     0.919      7613\n",
      "weighted avg      0.923     0.921     0.921      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, train_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test=X_test.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_preds=pipe.predict(X_test)\n",
    "output = pd.DataFrame({'id': test.id,\n",
    "                       'target': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
